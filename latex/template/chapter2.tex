\chapter{Related Work}

Research on online toxicity has primarily focused on centralized social media platforms like Twitter and Facebook \cite{fan:2022,nicholson:2023}. These studies have examined various aspects of toxic behavior, including its diffusion patterns, impact on communities, and moderation strategies. However, decentralized online social networks (DOSNs) like Mastodon present unique challenges and opportunities for studying toxicity due to their federated architecture and distributed moderation systems \cite{bono:2024}. This chapter reviews relevant literature on Mastodon communities, decentralized moderation, and large-scale toxicity analysis to situate our research within the existing work.

\paragraph{Behaviour of Mastodon Communities}
Mastodon has emerged as a prominent DOSN, offering an alternative to centralized platforms by enabling users to join independent instances that form a federated network \cite{zulli:2020}. Unlike traditional social media, Mastodon's architecture allows for diverse communities with distinct norms and moderation practices \cite{la_cava:2021}. Instances work independently but connect through ActivityPub, forming a network where content flows between servers \cite{mastodon:docs}. This setup enables researchers to study how communities form. Users behave differently than on centralized platforms like Twitter, especially looking at how groups separate or interact across instances \cite{zignani:2018}.

The topology of Mastodon communities exhibits unique characteristics. \citet{zulli:2020} found that Mastodon instances often form around specific interests, identities, or ideologies, leading to more homogeneous communities. This clustering behavior influences information consumption patterns and user relationships, with instances developing distinct footprints based on their thematic focus \cite{la_cava:2021}. Such organizational differences suggest that toxicity patterns in Mastodon may follow different dynamics than those observed in centralized platforms.

\paragraph{Decentralized Moderation Challenges}
The federated nature of Mastodon introduces novel challenges for content moderation, as each instance maintains its own policies and enforcement mechanisms. \citet{bono:2024} found that instance administrators primarily rely on blocklisting to moderate content, preventing users from interacting with servers hosting harmful material. This decentralized approach allows for customized moderation but creates inconsistencies across the network, as blocklisting decisions vary significantly between instances \cite{nicholson:2023}. The study found that blocklists mainly ban instances containing spam, hate speech, or adult content. Many administrators use these shared blocklists without carefully checking them first \cite{bono:2024}.

\citet{nicholson:2023} examined Mastodon's rules and discovered they focus more on preventing harassment and hate speech than similar Reddit communities. Their research showed that Mastodon's decentralized approach creates different types of rules across instances. Some rules specifically target e.g. discrimination, while others use general community guidelines. Because each instance has its own moderation approach, studying toxicity becomes more challenging, as what users see and experience varies significantly depending on which instance they join.

\paragraph{Large-Scale Toxicity Analysis}
Existing approaches to toxicity analysis have typically focused on specific events or short timeframes on centralized platforms. For example \citet{fan:2022} developed a comprehensive workflow for analyzing toxicity during health crises, combining topic modeling and network analysis to understand toxic discourse patterns. Their approach, which processed over 1.6 million tweets during the 2022 Mpox outbreak, revealed how toxicity spreads differently through mentions versus retweets and identified influential users in toxic discourse networks \cite{fan:2022}.

The scale and distributed nature of Mastodon data require specialized processing pipelines. Existing research has highlighted the need for efficient deduplication methods when analyzing federated content, as toots often propagate across multiple instances \cite{bono:2024}.